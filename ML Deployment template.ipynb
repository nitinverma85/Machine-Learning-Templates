{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Deployment\n",
    "\n",
    "### Steps\n",
    "\n",
    "Step 1: **Make ML model in a virtual environment** :\n",
    "Step 2: **Make an API endpoint for the ML model** : \n",
    "Step 3. **Dockerise it** : Helps productionise the API and makes the model more scalable\n",
    "Step 4. **Deploy the docker container on EC2 or Kubernetes ** : \n",
    "\n",
    "\n",
    "#### Step 1: **Make ML model in a virtual environment** :\n",
    "- Make a pickle file of the model and save it\n",
    "\n",
    "#### Step 2 : **Make an API endpoint for the ML model** : \n",
    "\n",
    "- Create a flask app and define routes. The main route should include reading the pickle model. One of the other routes should include predicting the output when user passes the inputs in the URL. \n",
    "\n",
    "- WSGI (Web server gateway interface) : Any user that wants to get results of our model needs to go to Web Server where WSGI file will redirect it to the Flask App to get the results. \n",
    "\n",
    "\n",
    "\n",
    "#### Step 3 : **Dockerise it**\n",
    "\n",
    "Introduction\n",
    "\n",
    "- When we make an ML model, it uses libraries that might be dependent on the OS and a hardware configuration. So, it might or might not work on every machine. Requirements.txt file that comes bundled with ML models in a new environment is not enough. \n",
    "\n",
    "- So, we dockerise by making a container for the ML App and include all dependencies in the docker. When we switch machines, we unpack everything from the docker in the new machine. So, it essentially standardises the environment. Build once, deploy anywhere. \n",
    "\n",
    "- Hence, a container is a type of software that packages up an application and all its dependencies so the application runs reliably from one computing environment to another. Docker is a company that provides containers. \n",
    " \n",
    "\n",
    "- Virtual machines (alternative to Dockers) : They also help in environment standardisation where we can have different environments configured (Hardware and software) in different virtual machines. Virtual machines create virtual environments over a web server, with each virtual machine having its own RAM, HD and network capabilities. \n",
    "\n",
    "- Docker containers : Dockers use virtualisation. Each docker contains its own process ID (CPU), network config, user root folder. In Docker, the containers running share the host OS kernel. A container is just a set of processes that are isolated from the rest of the system. Each VM has Operating system (OS).\n",
    "\n",
    "- Dockers are similar to virtual machines (both help in environment standardisation) except one major difference. These virtual machines can't use each others resources if one virtual machine is underutilised (since each machine has a separate OS) while one is over utilised. Docker containers can use each others resources.  \n",
    "\n",
    "How to make a docker container\n",
    "\n",
    " - Make a dockerfile and execute it using docker build -t <Name of docker App>. Once you execute it, dockerfile would run which contains all commands. \n",
    " - Ensure the main API file is in the same folder   \n",
    " - Dockerfile includes FROM (copy base image containing OS from docker), COPY (copy your API file, requirments.txt file, classifier pkl file into Docker root folder), EXPOSE (expose your docker image to a particular port), Working directory (usually your Docker root folder), RUN(install requirements.txt), CMD (Run your main app)\n",
    "    \n",
    "    \n",
    "How to run a docker container\n",
    "\n",
    "- Docker run -p <Port>:<Port> <Name of docker app>\n",
    "\n",
    "\n",
    "\n",
    "#### Step 4. **Deploy the docker container on EC2 or Kubernetes ** : \n",
    "\n",
    "- Kubernetes is a system for running and coordinating containerized applications across a cluster of machines (includes scaling, load balancing etc.)\n",
    "\n",
    "- Docker is a software that allows you to containerize applications while Kubernetes is a container management system that allows to create, scale and monitor hundreds and thousands of containers.\n",
    "\n",
    "- Google Kubernetes Engine is implementation of Googleâ€™s open source Kubernetes on Google Cloud Platform. Other popular alternatives to GKE are Amazon ECS and Microsoft Azure Kubernetes Service.\n",
    "\n",
    "- Steps include to upload the docker image to Google Container Registry. Then create a cluster (VM instance) running a Kubernetes. Then deploy the docker image from the GCR to Google Kubernetes Engine cluster. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1372, 5)\n",
      "0    762\n",
      "1    610\n",
      "Name: class, dtype: int64\n",
      "Index(['variance', 'skewness', 'curtosis', 'entropy', 'class'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "variance   -2.8829\n",
       "skewness    3.8964\n",
       "curtosis   -0.1888\n",
       "entropy    -1.1672\n",
       "class       1.0000\n",
       "Name: 1000, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df=pd.read_csv('./Data/BankNote_Authentication.csv')\n",
    "print(df.shape)\n",
    "print(df['class'].value_counts())\n",
    "df.head()\n",
    "\n",
    "X= df.iloc[:,:-1]\n",
    "y= df.iloc[:,-1]\n",
    "\n",
    "X_train,X_test,y_train, y_test = train_test_split(X,y,test_size=.3, random_state=0) \n",
    "print(df.columns)\n",
    "df.iloc[1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9878640776699029\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "classifier=RandomForestClassifier()\n",
    "classifier.fit(X_train,y_train)\n",
    "\n",
    "y_pred=classifier.predict(X_test)\n",
    "\n",
    "accuracy_score=accuracy_score(y_test,y_pred)\n",
    "print(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "pickle_out = open('classifier.pkl','wb')\n",
    "pickle.dump(classifier, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
