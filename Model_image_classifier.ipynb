{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import warnings\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sn\n",
    "import pandas as pd \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to store cropped face images in cropped folder\n",
    "# Face detection using Haar cascades is a machine learning based approach where a cascade function is trained with a set of input data\n",
    "# The detection works only on grayscale images\n",
    "# Faces contains a list of coordinates for the rectangular regions where faces were found. \n",
    "face_cascade = cv2.CascadeClassifier('./opencv/haarcascades/haarcascade_frontalface_default.xml')\n",
    "eye_cascade = cv2.CascadeClassifier(\"./opencv/haarcascades/haarcascade_eye.xml\")\n",
    "#save the image(i) in the same directory\n",
    "def get_cropped_image_if_2_eyes(image_path):\n",
    "    img = cv2.imread(image_path)\n",
    "    if(img is not None):\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        faces = face_cascade.detectMultiScale(gray, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            roi_gray = gray[y:y+h, x:x+w]\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "            if len(eyes) >= 2:\n",
    "                return roi_color   \n",
    "    else:\n",
    "        exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Data/SW', './Data/MS', './Data/RF']"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the paths of original images\n",
    "\n",
    "path_to_data = \"./Data/\"\n",
    "path_to_cr_data = \"./Data/cropped/\"\n",
    "\n",
    "import os\n",
    "img_dirs = []\n",
    "for entry in os.scandir(path_to_data):\n",
    "    if entry.is_dir():\n",
    "        if(entry.path!='./Data/.ipynb_checkpoints' and entry.path!='./Data/cropped'):\n",
    "            img_dirs.append(entry.path)\n",
    "        \n",
    "img_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove smaller face images folder if it already exists, else make a new one\n",
    "\n",
    "import shutil\n",
    "if os.path.exists(path_to_cr_data):\n",
    "     shutil.rmtree(path_to_cr_data)\n",
    "os.mkdir(path_to_cr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating cropped images in folder:  ./Data/cropped/SW\n",
      "Generating cropped images in folder:  ./Data/cropped/MS\n",
      "Generating cropped images in folder:  ./Data/cropped/RF\n"
     ]
    }
   ],
   "source": [
    "# Store cropped face images in cropped folder\n",
    "\n",
    "cropped_image_dirs = []\n",
    "celebrity_file_names_dict = {}\n",
    "for img_dir in img_dirs:\n",
    "    count = 1\n",
    "    celebrity_name = img_dir.split('/')[-1]\n",
    "    celebrity_file_names_dict[celebrity_name] = []\n",
    "    for entry in os.scandir(img_dir):\n",
    "        roi_color = get_cropped_image_if_2_eyes(entry.path)\n",
    "        if roi_color is not None:\n",
    "            cropped_folder = path_to_cr_data + celebrity_name\n",
    "            if not os.path.exists(cropped_folder):\n",
    "                os.makedirs(cropped_folder)\n",
    "                cropped_image_dirs.append(cropped_folder)\n",
    "                print(\"Generating cropped images in folder: \",cropped_folder)\n",
    "            cropped_file_name = celebrity_name + str(count) + \".png\"\n",
    "            cropped_file_path = cropped_folder + \"/\" + cropped_file_name\n",
    "            cv2.imwrite(cropped_file_path, roi_color)\n",
    "            celebrity_file_names_dict[celebrity_name].append(cropped_file_path)\n",
    "            count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wavelet transform of images\n",
    "\n",
    "import numpy as np\n",
    "import pywt\n",
    "import cv2    \n",
    "\n",
    "def w2d(img, mode='haar', level=1):\n",
    "    imArray = img\n",
    "    #Datatype conversions\n",
    "    #convert to grayscale\n",
    "    imArray = cv2.cvtColor( imArray,cv2.COLOR_RGB2GRAY )\n",
    "    #convert to float\n",
    "    imArray =  np.float32(imArray)   \n",
    "    imArray /= 255;\n",
    "    # compute coefficients \n",
    "    coeffs=pywt.wavedec2(imArray, mode, level=level)\n",
    "\n",
    "    #Process Coefficients\n",
    "    coeffs_H=list(coeffs)  \n",
    "    coeffs_H[0] *= 0;  \n",
    "\n",
    "    # reconstruction\n",
    "    imArray_H=pywt.waverec2(coeffs_H, mode);\n",
    "    imArray_H *= 255;\n",
    "    imArray_H =  np.uint8(imArray_H)\n",
    "\n",
    "    return imArray_H\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Example wavelet transform for MS Dhoni Image\n",
    "\n",
    "# img = cv2.imread('./Data/MSD/MSD.jpg')\n",
    "# plt.imshow(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# roi_color=get_cropped_image_if_2_eyes('./Data/MSD/MSD.jpg')\n",
    "# plt.imshow(roi_color, cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropped_img = np.array(roi_color)\n",
    "# im_har = w2d(cropped_img,'db1',5)\n",
    "# plt.imshow(im_har, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making one image containing original cut image and wavelet transformed image and adding it to X\n",
    "# \n",
    "\n",
    "X=[]\n",
    "y=[]\n",
    "classdict={}\n",
    "count=0\n",
    "\n",
    "for celebrity,training_images in celebrity_file_names_dict.items():\n",
    "    classdict[celebrity]=count\n",
    "    count=count+1\n",
    "\n",
    "for celebrity,training_images in celebrity_file_names_dict.items():\n",
    "    for image in training_images:\n",
    "        img=cv2.imread(image)\n",
    "        if img is None:\n",
    "            print('No Image')\n",
    "            continue\n",
    "        scaled_raw_img=cv2.resize(img,(32,32))\n",
    "        im_har = w2d(img,'db1',5)\n",
    "        scaled_img_har=cv2.resize(im_har,(32,32))\n",
    "        combined_img=np.vstack((scaled_raw_img.reshape(32*32*3,1),scaled_img_har.reshape(32*32,1)))\n",
    "        X.append(combined_img)\n",
    "        y.append(classdict[celebrity])\n",
    "X=np.array(X).reshape(len(X),4096).astype(float)\n",
    "y=np.array(y).reshape(len(y),1).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is 0.8903318903318903\n",
      "Recall is 0.9\n",
      "Accuracy is 0.8918918918918919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.87      0.90        15\n",
      "         1.0       0.91      0.83      0.87        12\n",
      "         2.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.89        37\n",
      "   macro avg       0.89      0.90      0.89        37\n",
      "weighted avg       0.90      0.89      0.89        37\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Actual')"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df=pd.DataFrame(X)\n",
    "df['Celebrity']=y\n",
    "\n",
    "X=df.drop('Celebrity',axis='columns')\n",
    "y=df['Celebrity']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n",
    "\n",
    "logisticRegression=LogisticRegression()\n",
    "logisticRegression.fit(X_train,y_train)\n",
    "y_pred=logisticRegression.predict(X_test)\n",
    "print(\"Precision is {}\".format(sklearn.metrics.precision_score(y_test, y_pred, average = \"macro\")))\n",
    "print(\"Recall is {}\".format(sklearn.metrics.recall_score(y_test, y_pred, average = \"macro\")))\n",
    "print(\"Accuracy is {}\".format(sklearn.metrics.accuracy_score(y_test, y_pred)))\n",
    "print(classification_report(y_test,y_pred))\n",
    "sn.heatmap(tf.math.confusion_matrix(labels=y_test, predictions=y_pred),annot=True,fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 0.8918918918918919\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.93      0.93        15\n",
      "         1.0       0.90      0.75      0.82        12\n",
      "         2.0       0.83      1.00      0.91        10\n",
      "\n",
      "    accuracy                           0.89        37\n",
      "   macro avg       0.89      0.89      0.89        37\n",
      "weighted avg       0.90      0.89      0.89        37\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(33.0, 0.5, 'Actual')"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Recall for class 1 is how many cases out of total were you able to predict for class 1. \n",
    "# Thinking about cancer, let's say 20 had cancer and you predicted 19 out of them correctly. \n",
    "# Recall is 95%\n",
    "\n",
    "\n",
    "# Precision for class 1 is How many you predicted class 1/How many actually are class 1. \n",
    "# Thinking about cancer, you predicted 100 mights have cancer and 20 of them actually had cancer\n",
    "# Precision is 20% \n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 5)\n",
    "pipe = Pipeline([('scaler',StandardScaler()),('svc',SVC(kernel='rbf',C=10))])\n",
    "pipe.fit(X_train,y_train)\n",
    "print(\"Accuracy is {}\".format(pipe.score(X_test,y_test)))\n",
    "print(classification_report(y_test,pipe.predict(X_test)))\n",
    "y_pred=pipe.predict(X_test)\n",
    "sn.heatmap(tf.math.confusion_matrix(labels=y_test, predictions=y_pred),annot=True,fmt='d')\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>best_params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>svm</td>\n",
       "      <td>0.840887</td>\n",
       "      <td>{'svc__C': 1, 'svc__kernel': 'rbf'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.798768</td>\n",
       "      <td>{'randomforestclassifier__n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>0.820197</td>\n",
       "      <td>{'logisticregression__C': 1}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model  best_score  \\\n",
       "0                  svm    0.840887   \n",
       "1        random_forest    0.798768   \n",
       "2  logistic_regression    0.820197   \n",
       "\n",
       "                                   best_params  \n",
       "0          {'svc__C': 1, 'svc__kernel': 'rbf'}  \n",
       "1  {'randomforestclassifier__n_estimators': 5}  \n",
       "2                 {'logisticregression__C': 1}  "
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GridSearchCV can try multiple algorithms and multiple hyperparameters\n",
    "# GrisSearch CV uses part of train set as validation set in order to find the best hyperparameter\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "model_params = {\n",
    "    'svm': {\n",
    "        'model': svm.SVC(gamma='auto',probability=True),\n",
    "        'params' : {\n",
    "            'svc__C': [1,10,100,1000],\n",
    "            'svc__kernel': ['rbf','linear']\n",
    "        }  \n",
    "    },\n",
    "    'random_forest': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params' : {\n",
    "            'randomforestclassifier__n_estimators': [1,5,10]\n",
    "        }\n",
    "    },\n",
    "    'logistic_regression' : {\n",
    "        'model': LogisticRegression(solver='liblinear',multi_class='auto'),\n",
    "        'params': {\n",
    "            'logisticregression__C': [1,5,10]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "scores = []\n",
    "best_estimators = {}\n",
    "import pandas as pd\n",
    "for algo, mp in model_params.items():\n",
    "    pipe = make_pipeline(StandardScaler(), mp['model'])\n",
    "    clf =  GridSearchCV(pipe, mp['params'], cv=5, return_train_score=False)\n",
    "    clf.fit(X_train, y_train)\n",
    "    scores.append({\n",
    "        'model': algo,\n",
    "        'best_score': clf.best_score_,\n",
    "        'best_params': clf.best_params_\n",
    "    })\n",
    "    best_estimators[algo] = clf.best_estimator_\n",
    "    \n",
    "df = pd.DataFrame(scores,columns=['model','best_score','best_params'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8918918918918919"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just trying svm on test set as well\n",
    "best_clf= best_estimators['svm']\n",
    "best_estimators['svm'].score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['saved_model.pkl']"
      ]
     },
     "execution_count": 441,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the model \n",
    "import joblib\n",
    "joblib.dump(best_clf, 'saved_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save dictionary\n",
    "import json\n",
    "with open(\"class_dictionary.json\",\"w\") as f:\n",
    "    f.write(json.dumps(classdict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
